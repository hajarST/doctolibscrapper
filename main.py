from playwright.sync_api import sync_playwright
import pandas as pd
import time

BASE_URL = "https://www.doctolib.fr/medecin-generaliste/?page="
START_PAGE = 1   # üîÅ Page de d√©part
END_PAGE = 2     # üîÅ Derni√®re page √† scraper (change ici pour 50, 100, etc.)

def scrape_doctolib():
    data = []

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False, slow_mo=120)
        context = browser.new_context()

        for page_number in range(START_PAGE, END_PAGE + 1):
            url = BASE_URL + str(page_number)
            print(f"\nüîç Chargement de la page {page_number} : {url}")
            page = context.new_page()
            page.goto(url, timeout=120000)
            page.wait_for_timeout(3000)

            # Scroll pour charger les r√©sultats dynamiques
            for _ in range(4):
                page.mouse.wheel(0, 3000)
                time.sleep(2)

            # ‚úÖ S√©lecteur corrig√© pour les vrais profils
            try:
                page.wait_for_selector("div.flex.justify-between > a[href*='/medecin-generaliste/']", timeout=15000)
                links = page.eval_on_selector_all(
                    "div.flex.justify-between > a[href*='/medecin-generaliste/']",
                    "elements => elements.map(el => el.href)"
                )
                links = list(set(links))
                print(f"üîó {len(links)} profils trouv√©s sur la page {page_number}.")
            except:
                print("‚ùå Aucune donn√©e trouv√©e sur cette page.")
                links = []

            # Boucle sur chaque profil
            for idx, link in enumerate(links):
                try:
                    profile_page = context.new_page()
                    profile_page.goto(link, timeout=60000)
                    profile_page.wait_for_timeout(2000)

                    # Nom
                    try:
                        profile_page.wait_for_selector("h1#profile-name-with-title span[itemprop='name']", timeout=5000)
                        name = profile_page.locator("h1#profile-name-with-title span[itemprop='name']").inner_text().strip()
                    except:
                        name = "Nom non trouv√©"

                    # Fonction
                    try:
                        fonction = profile_page.locator("div.dl-profile-header-speciality span").inner_text().strip()
                    except:
                        fonction = "Fonction non trouv√©e"

                    # T√©l√©phone
                    try:
                        phone = profile_page.locator("div.dl-profile-box:has(h3:has-text('Coordonn√©es')) div.flex").inner_text().strip()
                    except:
                        phone = "T√©l√©phone non trouv√©"

                    # Exp√©rience
                    experience_list = []
                    try:
                        exp_container = profile_page.locator("h3.dl-profile-card-title:has-text('Exp√©rience')").locator("..")
                        entries = exp_container.locator("div.dl-profile-text.dl-profile-entry")
                        for i in range(entries.count()):
                            time_text = entries.nth(i).locator("div.dl-profile-entry-time").inner_text().strip()
                            label_text = entries.nth(i).locator("p.dl-profile-entry-label").inner_text().strip()
                            if time_text:
                                experience_list.append(f"{label_text} ({time_text})")
                            else:
                                experience_list.append(label_text)
                        experience = "\n".join(experience_list)
                    except:
                        experience = "Exp√©rience non pr√©cis√©e"

                    # Dipl√¥mes
                    dipl√¥mes_list = []
                    try:
                        dipl_container = profile_page.locator("h3.dl-profile-card-title:has-text('Dipl√¥mes nationaux et universitaires')").locator("..")
                        dipl_entries = dipl_container.locator("div.dl-profile-text.dl-profile-entry")
                        for i in range(dipl_entries.count()):
                            year = dipl_entries.nth(i).locator("div.dl-profile-entry-time").inner_text().strip()
                            label = dipl_entries.nth(i).locator("p.dl-profile-entry-label").inner_text().strip()
                            dipl√¥mes_list.append(f"{label} ({year})")
                        diplomes = "\n".join(dipl√¥mes_list)
                    except:
                        diplomes = "Non pr√©cis√©s"

                    # Adresse
                    try:
                        cabinet_name = profile_page.locator("div.dl-profile-text div .dl-profile-practice-name").inner_text().strip()
                    except:
                        cabinet_name = ""

                    try:
                        address_element = profile_page.locator("div.dl-profile-text div div[id^='practice-address-']")
                        address_text = address_element.inner_text().strip()
                    except:
                        address_text = ""

                    if cabinet_name or address_text:
                        address = f"{cabinet_name} - {address_text}".strip(" -")
                    else:
                        address = "Adresse non trouv√©e"

                    # Horaires
                    try:
                        horaires_list = []
                        horaires_elements = profile_page.locator("div.js-opening-hours ul li div[itemprop='openingHours']")
                        for i in range(horaires_elements.count()):
                            horaires_list.append(horaires_elements.nth(i).inner_text().strip())
                        horaires = "\n".join(horaires_list)
                    except:
                        horaires = "Horaires non trouv√©s"

                    # Num√©ro RPPS
                    try:
                        rpps = profile_page.locator("p:has-text('Num√©ro RPPS') + p").inner_text().strip()
                    except:
                        rpps = "Non trouv√©"

                    # SIREN
                    try:
                        siren = profile_page.locator("p:has-text('SIREN') + p").inner_text().strip()
                    except:
                        siren = "Non trouv√©"

                    # Ajouter au tableau
                    data.append({
                        "Nom": name,
                        "Fonction": fonction,
                        "T√©l√©phone": phone,
                        "Exp√©rience": experience,
                        "Dipl√¥mes": diplomes,
                        "Adresse": address,
                        "Horaires": horaires,
                        "Num√©ro RPPS": rpps,
                        "SIREN": siren,
                        "Lien": link
                    })

                    print(f"‚úÖ Profil {len(data)} extrait : {name} | üîó {link}")
                    profile_page.close()

                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur lors de l'extraction : {e}")
                    continue

            page.close()

        browser.close()

    # Sauvegarde Excel
    df = pd.DataFrame(data)
    df.to_excel(f"doctolib_doctors_page_{START_PAGE}_to_{END_PAGE}.xlsx", index=False, engine='openpyxl')
    print(f"\nüìÅ Donn√©es enregistr√©es dans doctolib_doctors_page_{START_PAGE}_to_{END_PAGE}.xlsx (Total : {len(data)} profils) ‚úÖ")

if __name__ == "__main__":
    scrape_doctolib()
